{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "id": "IJTpQNHiLqGZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://anu9rng:****@rb-artifactory.bosch.com/artifactory/api/pypi/python-virtual/simple\n",
      "Requirement already up-to-date: scikit-learn in c:\\users\\disrct\\appdata\\roaming\\python\\python38\\site-packages (1.3.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.5.0 in c:\\program files\\anaconda3\\lib\\site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=1.1.1 in c:\\users\\disrct\\appdata\\roaming\\python\\python38\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in c:\\program files\\anaconda3\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.17.3 in c:\\program files\\anaconda3\\lib\\site-packages (from scikit-learn) (1.18.5)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://anu9rng:****@rb-artifactory.bosch.com/artifactory/api/pypi/python-virtual/simple\n",
      "Requirement already satisfied: pandas in c:\\program files\\anaconda3\\lib\\site-packages (1.0.5)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\program files\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\program files\\anaconda3\\lib\\site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\program files\\anaconda3\\lib\\site-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\program files\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://anu9rng:****@rb-artifactory.bosch.com/artifactory/api/pypi/python-virtual/simple\n",
      "Requirement already satisfied: jolib in c:\\users\\disrct\\appdata\\roaming\\python\\python38\\site-packages (0.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn\n",
    "!pip install pandas\n",
    "!pip install jolib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WofNZINJPE7z"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from joblib import load, dump\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/stefanoleone992/fifa-22-complete-player-dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "_pO-mbe3PSJk"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../df/players_22.csv\") # Open csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"club_position\"] = df[\"club_position\"].fillna(\"SUB\") # Turn nan to SUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df[\"club_position\"] != \"RES\") & (df[\"club_position\"] != \"SUB\")] # Exclude SUB e RES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "QJ0zii3VPn_9"
   },
   "outputs": [],
   "source": [
    "def convertPosition(data): # Change to Atk, Mid, Def and Gk\n",
    "    if (data == \"GK\"):\n",
    "        return 0\n",
    "    elif (\"B\" in data):\n",
    "        return 1\n",
    "    elif(\"M\" in data):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "df[\"position\"] = df[\"club_position\"].apply(convertPosition)\n",
    "\n",
    "X = df.drop([\"position\", \"club_position\"], axis=1)\n",
    "y = df[[\"position\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "l9XJXSdwwcZl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sofifa_id, player_url, short_name, long_name, player_positions, overall, potential, value_eur, wage_eur, age, dob, height_cm, weight_kg, club_team_id, club_name, league_name, league_level, club_position, club_jersey_number, club_loaned_from, club_joined, club_contract_valid_until, nationality_id, nationality_name, nation_team_id, nation_position, nation_jersey_number, preferred_foot, weak_foot, skill_moves, international_reputation, work_rate, body_type, real_face, release_clause_eur, player_tags, player_traits, pace, shooting, passing, dribbling, defending, physic, attacking_crossing, attacking_finishing, attacking_heading_accuracy, attacking_short_passing, attacking_volleys, skill_dribbling, skill_curve, skill_fk_accuracy, skill_long_passing, skill_ball_control, movement_acceleration, movement_sprint_speed, movement_agility, movement_reactions, movement_balance, power_shot_power, power_jumping, power_stamina, power_strength, power_long_shots, mentality_aggression, mentality_interceptions, mentality_positioning, mentality_vision, mentality_penalties, mentality_composure, defending_marking_awareness, defending_standing_tackle, defending_sliding_tackle, goalkeeping_diving, goalkeeping_handling, goalkeeping_kicking, goalkeeping_positioning, goalkeeping_reflexes, goalkeeping_speed, ls, st, rs, lw, lf, cf, rf, rw, lam, cam, ram, lm, lcm, cm, rcm, rm, lwb, ldm, cdm, rdm, rwb, lb, lcb, cb, rcb, rb, gk, player_face_url, club_logo_url, club_flag_url, nation_logo_url, nation_flag_url, "
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "  print(col, end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "gC7QUyXZQQVl"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>potential</th>\n",
       "      <th>value_eur</th>\n",
       "      <th>wage_eur</th>\n",
       "      <th>age</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>club_name</th>\n",
       "      <th>league_name</th>\n",
       "      <th>league_level</th>\n",
       "      <th>nationality_name</th>\n",
       "      <th>preferred_foot</th>\n",
       "      <th>weak_foot</th>\n",
       "      <th>skill_moves</th>\n",
       "      <th>international_reputation</th>\n",
       "      <th>work_rate</th>\n",
       "      <th>body_type</th>\n",
       "      <th>real_face</th>\n",
       "      <th>release_clause_eur</th>\n",
       "      <th>pace</th>\n",
       "      <th>shooting</th>\n",
       "      <th>passing</th>\n",
       "      <th>dribbling</th>\n",
       "      <th>defending</th>\n",
       "      <th>physic</th>\n",
       "      <th>attacking_crossing</th>\n",
       "      <th>attacking_finishing</th>\n",
       "      <th>attacking_heading_accuracy</th>\n",
       "      <th>attacking_short_passing</th>\n",
       "      <th>attacking_volleys</th>\n",
       "      <th>skill_dribbling</th>\n",
       "      <th>skill_curve</th>\n",
       "      <th>skill_fk_accuracy</th>\n",
       "      <th>skill_long_passing</th>\n",
       "      <th>skill_ball_control</th>\n",
       "      <th>movement_acceleration</th>\n",
       "      <th>movement_sprint_speed</th>\n",
       "      <th>movement_agility</th>\n",
       "      <th>movement_reactions</th>\n",
       "      <th>movement_balance</th>\n",
       "      <th>power_shot_power</th>\n",
       "      <th>power_jumping</th>\n",
       "      <th>power_stamina</th>\n",
       "      <th>power_strength</th>\n",
       "      <th>power_long_shots</th>\n",
       "      <th>mentality_aggression</th>\n",
       "      <th>mentality_interceptions</th>\n",
       "      <th>mentality_positioning</th>\n",
       "      <th>mentality_vision</th>\n",
       "      <th>mentality_penalties</th>\n",
       "      <th>mentality_composure</th>\n",
       "      <th>defending_marking_awareness</th>\n",
       "      <th>defending_standing_tackle</th>\n",
       "      <th>defending_sliding_tackle</th>\n",
       "      <th>goalkeeping_diving</th>\n",
       "      <th>goalkeeping_handling</th>\n",
       "      <th>goalkeeping_kicking</th>\n",
       "      <th>goalkeeping_positioning</th>\n",
       "      <th>goalkeeping_reflexes</th>\n",
       "      <th>goalkeeping_speed</th>\n",
       "      <th>ls</th>\n",
       "      <th>st</th>\n",
       "      <th>rs</th>\n",
       "      <th>lw</th>\n",
       "      <th>lf</th>\n",
       "      <th>cf</th>\n",
       "      <th>rf</th>\n",
       "      <th>rw</th>\n",
       "      <th>lam</th>\n",
       "      <th>cam</th>\n",
       "      <th>ram</th>\n",
       "      <th>lm</th>\n",
       "      <th>lcm</th>\n",
       "      <th>cm</th>\n",
       "      <th>rcm</th>\n",
       "      <th>rm</th>\n",
       "      <th>lwb</th>\n",
       "      <th>ldm</th>\n",
       "      <th>cdm</th>\n",
       "      <th>rdm</th>\n",
       "      <th>rwb</th>\n",
       "      <th>lb</th>\n",
       "      <th>lcb</th>\n",
       "      <th>cb</th>\n",
       "      <th>rcb</th>\n",
       "      <th>rb</th>\n",
       "      <th>gk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>78000000.0</td>\n",
       "      <td>320000.0</td>\n",
       "      <td>34</td>\n",
       "      <td>170</td>\n",
       "      <td>72</td>\n",
       "      <td>470</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>144300000.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>85</td>\n",
       "      <td>95</td>\n",
       "      <td>70</td>\n",
       "      <td>91</td>\n",
       "      <td>88</td>\n",
       "      <td>96</td>\n",
       "      <td>93</td>\n",
       "      <td>94</td>\n",
       "      <td>91</td>\n",
       "      <td>96</td>\n",
       "      <td>91</td>\n",
       "      <td>80</td>\n",
       "      <td>91</td>\n",
       "      <td>94</td>\n",
       "      <td>95</td>\n",
       "      <td>86</td>\n",
       "      <td>68</td>\n",
       "      <td>72</td>\n",
       "      <td>69</td>\n",
       "      <td>94</td>\n",
       "      <td>44</td>\n",
       "      <td>40</td>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "      <td>75</td>\n",
       "      <td>96</td>\n",
       "      <td>20</td>\n",
       "      <td>35</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>91</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>91</td>\n",
       "      <td>66</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>66</td>\n",
       "      <td>61</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>119500000.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>32</td>\n",
       "      <td>185</td>\n",
       "      <td>81</td>\n",
       "      <td>241</td>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>197200000.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>71</td>\n",
       "      <td>95</td>\n",
       "      <td>90</td>\n",
       "      <td>85</td>\n",
       "      <td>89</td>\n",
       "      <td>85</td>\n",
       "      <td>79</td>\n",
       "      <td>85</td>\n",
       "      <td>70</td>\n",
       "      <td>88</td>\n",
       "      <td>77</td>\n",
       "      <td>79</td>\n",
       "      <td>77</td>\n",
       "      <td>93</td>\n",
       "      <td>82</td>\n",
       "      <td>90</td>\n",
       "      <td>85</td>\n",
       "      <td>76</td>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "      <td>81</td>\n",
       "      <td>49</td>\n",
       "      <td>95</td>\n",
       "      <td>81</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>85</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>85</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>84</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>84</td>\n",
       "      <td>64</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>64</td>\n",
       "      <td>61</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>45000000.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>36</td>\n",
       "      <td>187</td>\n",
       "      <td>83</td>\n",
       "      <td>412</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>83300000.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>87</td>\n",
       "      <td>95</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>86</td>\n",
       "      <td>88</td>\n",
       "      <td>81</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>88</td>\n",
       "      <td>85</td>\n",
       "      <td>88</td>\n",
       "      <td>86</td>\n",
       "      <td>94</td>\n",
       "      <td>74</td>\n",
       "      <td>94</td>\n",
       "      <td>95</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>93</td>\n",
       "      <td>63</td>\n",
       "      <td>29</td>\n",
       "      <td>95</td>\n",
       "      <td>76</td>\n",
       "      <td>88</td>\n",
       "      <td>95</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>88</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>86</td>\n",
       "      <td>63</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>63</td>\n",
       "      <td>60</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>129000000.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>29</td>\n",
       "      <td>175</td>\n",
       "      <td>68</td>\n",
       "      <td>470</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>238700000.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>85</td>\n",
       "      <td>83</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>95</td>\n",
       "      <td>88</td>\n",
       "      <td>87</td>\n",
       "      <td>81</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "      <td>89</td>\n",
       "      <td>96</td>\n",
       "      <td>89</td>\n",
       "      <td>84</td>\n",
       "      <td>80</td>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>53</td>\n",
       "      <td>81</td>\n",
       "      <td>63</td>\n",
       "      <td>37</td>\n",
       "      <td>86</td>\n",
       "      <td>90</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>89</td>\n",
       "      <td>67</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>67</td>\n",
       "      <td>62</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>62</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>125500000.0</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "      <td>70</td>\n",
       "      <td>411</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>232200000.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>94</td>\n",
       "      <td>82</td>\n",
       "      <td>55</td>\n",
       "      <td>94</td>\n",
       "      <td>82</td>\n",
       "      <td>88</td>\n",
       "      <td>85</td>\n",
       "      <td>83</td>\n",
       "      <td>93</td>\n",
       "      <td>91</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>79</td>\n",
       "      <td>91</td>\n",
       "      <td>78</td>\n",
       "      <td>91</td>\n",
       "      <td>63</td>\n",
       "      <td>89</td>\n",
       "      <td>74</td>\n",
       "      <td>91</td>\n",
       "      <td>76</td>\n",
       "      <td>66</td>\n",
       "      <td>88</td>\n",
       "      <td>94</td>\n",
       "      <td>83</td>\n",
       "      <td>89</td>\n",
       "      <td>68</td>\n",
       "      <td>65</td>\n",
       "      <td>53</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>88</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>88</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>79</td>\n",
       "      <td>75</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>75</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  potential    value_eur  wage_eur  age  height_cm  weight_kg  \\\n",
       "0       93         93   78000000.0  320000.0   34        170         72   \n",
       "1       92         92  119500000.0  270000.0   32        185         81   \n",
       "2       91         91   45000000.0  270000.0   36        187         83   \n",
       "3       91         91  129000000.0  270000.0   29        175         68   \n",
       "4       91         91  125500000.0  350000.0   30        181         70   \n",
       "\n",
       "   club_name  league_name  league_level  nationality_name  preferred_foot  \\\n",
       "0        470           19           1.0                 4               0   \n",
       "1        241           21           1.0               107               1   \n",
       "2        412           17           1.0               108               1   \n",
       "3        470           19           1.0                15               1   \n",
       "4        411           17           1.0                11               1   \n",
       "\n",
       "   weak_foot  skill_moves  international_reputation  work_rate  body_type  \\\n",
       "0          4            4                         5          7          9   \n",
       "1          4            4                         5          2          9   \n",
       "2          4            5                         5          1          9   \n",
       "3          5            5                         5          2          9   \n",
       "4          5            4                         4          0          9   \n",
       "\n",
       "   real_face  release_clause_eur  pace  shooting  passing  dribbling  \\\n",
       "0          1         144300000.0  85.0      92.0     91.0       95.0   \n",
       "1          1         197200000.0  78.0      92.0     79.0       86.0   \n",
       "2          1          83300000.0  87.0      94.0     80.0       88.0   \n",
       "3          1         238700000.0  91.0      83.0     86.0       94.0   \n",
       "4          1         232200000.0  76.0      86.0     93.0       88.0   \n",
       "\n",
       "   defending  physic  attacking_crossing  attacking_finishing  \\\n",
       "0       34.0    65.0                  85                   95   \n",
       "1       44.0    82.0                  71                   95   \n",
       "2       34.0    75.0                  87                   95   \n",
       "3       37.0    63.0                  85                   83   \n",
       "4       64.0    78.0                  94                   82   \n",
       "\n",
       "   attacking_heading_accuracy  attacking_short_passing  attacking_volleys  \\\n",
       "0                          70                       91                 88   \n",
       "1                          90                       85                 89   \n",
       "2                          90                       80                 86   \n",
       "3                          63                       86                 86   \n",
       "4                          55                       94                 82   \n",
       "\n",
       "   skill_dribbling  skill_curve  skill_fk_accuracy  skill_long_passing  \\\n",
       "0               96           93                 94                  91   \n",
       "1               85           79                 85                  70   \n",
       "2               88           81                 84                  77   \n",
       "3               95           88                 87                  81   \n",
       "4               88           85                 83                  93   \n",
       "\n",
       "   skill_ball_control  movement_acceleration  movement_sprint_speed  \\\n",
       "0                  96                     91                     80   \n",
       "1                  88                     77                     79   \n",
       "2                  88                     85                     88   \n",
       "3                  95                     93                     89   \n",
       "4                  91                     76                     76   \n",
       "\n",
       "   movement_agility  movement_reactions  movement_balance  power_shot_power  \\\n",
       "0                91                  94                95                86   \n",
       "1                77                  93                82                90   \n",
       "2                86                  94                74                94   \n",
       "3                96                  89                84                80   \n",
       "4                79                  91                78                91   \n",
       "\n",
       "   power_jumping  power_stamina  power_strength  power_long_shots  \\\n",
       "0             68             72              69                94   \n",
       "1             85             76              86                87   \n",
       "2             95             77              77                93   \n",
       "3             64             81              53                81   \n",
       "4             63             89              74                91   \n",
       "\n",
       "   mentality_aggression  mentality_interceptions  mentality_positioning  \\\n",
       "0                    44                       40                     93   \n",
       "1                    81                       49                     95   \n",
       "2                    63                       29                     95   \n",
       "3                    63                       37                     86   \n",
       "4                    76                       66                     88   \n",
       "\n",
       "   mentality_vision  mentality_penalties  mentality_composure  \\\n",
       "0                95                   75                   96   \n",
       "1                81                   90                   88   \n",
       "2                76                   88                   95   \n",
       "3                90                   93                   93   \n",
       "4                94                   83                   89   \n",
       "\n",
       "   defending_marking_awareness  defending_standing_tackle  \\\n",
       "0                           20                         35   \n",
       "1                           35                         42   \n",
       "2                           24                         32   \n",
       "3                           35                         32   \n",
       "4                           68                         65   \n",
       "\n",
       "   defending_sliding_tackle  goalkeeping_diving  goalkeeping_handling  \\\n",
       "0                        24                   6                    11   \n",
       "1                        19                  15                     6   \n",
       "2                        24                   7                    11   \n",
       "3                        29                   9                     9   \n",
       "4                        53                  15                    13   \n",
       "\n",
       "   goalkeeping_kicking  goalkeeping_positioning  goalkeeping_reflexes  \\\n",
       "0                   15                       14                     8   \n",
       "1                   12                        8                    10   \n",
       "2                   15                       14                    11   \n",
       "3                   15                       15                    11   \n",
       "4                    5                       10                    13   \n",
       "\n",
       "   goalkeeping_speed  ls  st  rs  lw  lf  cf  rf  rw  lam  cam  ram  lm  lcm  \\\n",
       "0                0.0  89  89  89  92  93  93  93  92   93   93   93  91   87   \n",
       "1                0.0  90  90  90  85  88  88  88  85   86   86   86  84   80   \n",
       "2                0.0  90  90  90  88  89  89  89  88   86   86   86  86   78   \n",
       "3                0.0  83  83  83  90  88  88  88  90   89   89   89  89   82   \n",
       "4                0.0  83  83  83  88  87  87  87  88   89   89   89  89   89   \n",
       "\n",
       "   cm  rcm  rm  lwb  ldm  cdm  rdm  rwb  lb  lcb  cb  rcb  rb  gk  \n",
       "0  87   87  91   66   64   64   64   66  61   50  50   50  61  19  \n",
       "1  80   80  84   64   66   66   66   64  61   60  60   60  61  19  \n",
       "2  78   78  86   63   59   59   59   63  60   53  53   53  60  20  \n",
       "3  82   82  89   67   63   63   63   67  62   50  50   50  62  20  \n",
       "4  89   89  89   79   80   80   80   79  75   69  69   69  75  21  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RW', 'ST', 'LW', 'RCM', 'GK', 'CF', 'CDM', 'LCB', 'RDM', 'RS',\n",
       "       'LCM', 'CAM', 'RCB', 'LDM', 'LB', 'RB', 'LM', 'RM', 'LS', 'CB',\n",
       "       'RWB', 'RF', 'CM', 'LWB', 'LAM', 'LF', 'RAM'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"club_position\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "id": "WowFOkU56c2r"
   },
   "outputs": [],
   "source": [
    "# DROP:\n",
    "# sofifa_id, player_url, short_name, long_name, player_positions, dob, club_team_id,\n",
    "# club_jersey_number, club_loaned_from, club_joined, club_contract_valid_until,\n",
    "# nationality_id, nation_team_id, nation_position, nation_jersey_number, player_tags,\n",
    "# player_traits, player_face_url, club_logo_url, club_flag_url, nation_logo_url, nation_flag_url\n",
    "\n",
    "# FIX:\n",
    "\n",
    "# Remove + and -\n",
    "# ls, st, rs, lw, lf, cf, rf, rw, lam, cam, ram, lm, lcm, cm, rcm, rm, lwb, ldm,\n",
    "# cdm, rdm, rwb, lb, lcb, cb, rcb, rb, gk\n",
    "\n",
    "# String to int (LabelEncoder)\n",
    "# club_name, league_name, nationality_name, preferred_foot,\n",
    "# work_rate, body_type, real_face\n",
    "\n",
    "# NaN to 0\n",
    "# goalkeeping_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "JWs2XE7-rc0l"
   },
   "outputs": [],
   "source": [
    "X.drop(['sofifa_id', 'player_url', 'short_name', 'long_name', 'player_positions', 'dob', 'club_team_id',\n",
    "            'club_jersey_number', 'club_loaned_from', 'club_joined', 'club_contract_valid_until',\n",
    "            'nationality_id', 'nation_team_id', 'nation_position', 'nation_jersey_number', 'player_tags',\n",
    "            'player_traits', 'player_face_url', 'club_logo_url', 'club_flag_url', 'nation_logo_url', 'nation_flag_url'], inplace=True, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "YjMxyfqQpwxe"
   },
   "outputs": [],
   "source": [
    "def convertToNumber(data):\n",
    "  if (\"+\" in data):\n",
    "    l = data.split(\"+\")[0]\n",
    "  elif (\"-\" in data):\n",
    "    l = data.split(\"-\")[0]\n",
    "  else:\n",
    "    l = data\n",
    "  return int(l)\n",
    "\n",
    "fixList = ['ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw', 'lam', 'cam', 'ram',\n",
    "           'lm', 'lcm', 'cm', 'rcm', 'rm', 'lwb', 'ldm', 'cdm', 'rdm', 'rwb',\n",
    "           'lb', 'lcb', 'cb', 'rcb', 'rb', 'gk']\n",
    "\n",
    "for fixColName in fixList:\n",
    "  X[fixColName] = X[fixColName].apply(convertToNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "oY56PbtL7sRQ"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "leList = ['club_name', 'league_name', 'nationality_name', 'preferred_foot',\n",
    "          'work_rate', 'body_type', 'real_face']\n",
    "\n",
    "for col in leList:\n",
    "  X[col] = le.fit_transform(X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "AuIilbqeOhWk"
   },
   "outputs": [],
   "source": [
    "y = y.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q7agcCq7Pe-D",
    "outputId": "eff95ae8-7da0-4814-db52-da4360446d81"
   },
   "outputs": [],
   "source": [
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "Q_6IfcuqBjqu"
   },
   "outputs": [],
   "source": [
    "X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "TZozF8ptnmll"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "VVtCheLCny0E",
    "outputId": "c5c24d47-25c8-4ce1-bd2c-33f6e0df116b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=124, min_samples_split=125)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=124, min_samples_split=125)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=124, min_samples_split=125)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(\n",
    "    min_samples_split=125,\n",
    "    max_depth=124\n",
    ")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OeoIj6_rn5ro",
    "outputId": "d1d4346b-c864-4a26-9243-27c2f5e1c506"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de teste:  0.813350615683733\n",
      "Dados de treino:  0.8503566796368353\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Dados de teste: \", accuracy)\n",
    "\n",
    "y_pred = model.predict(X_train)\n",
    "accuracy_train_data = accuracy_score(y_train, y_pred)\n",
    "print(\"Dados de treino: \", accuracy_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-4f5b15431fdf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdifferential_evolution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentialevolution.py\u001b[0m in \u001b[0;36mdifferential_evolution\u001b[1;34m(func, bounds, args, strategy, maxiter, popsize, tol, mutation, recombination, seed, callback, disp, polish, init, atol, updating, workers, constraints)\u001b[0m\n\u001b[0;32m    306\u001b[0m                                      \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m                                      constraints=constraints) as solver:\n\u001b[1;32m--> 308\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentialevolution.py\u001b[0m in \u001b[0;36msolve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[1;31m# evolve the population by a generation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m                 \u001b[0mwarning_flag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentialevolution.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1073\u001b[0m                     \u001b[0mfeasible\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1074\u001b[0m                     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1075\u001b[1;33m                     \u001b[0menergy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1076\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nfev\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1077\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentialevolution.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1260\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1261\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-4f5b15431fdf>\u001b[0m in \u001b[0;36mfind_accuracy\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     )\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mpartial_fit_and_fitted\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1145\u001b[1;33m                 \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m             with config_context(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    636\u001b[0m         \u001b[0maccepted\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m         \"\"\"\n\u001b[1;32m--> 638\u001b[1;33m         validate_parameter_constraints(\n\u001b[0m\u001b[0;32m    639\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parameter_constraints\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\_param_validation.py\u001b[0m in \u001b[0;36mvalidate_parameter_constraints\u001b[1;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[0;32m     94\u001b[0m                 )\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             raise InvalidParameterError(\n\u001b[0m\u001b[0;32m     97\u001b[0m                 \u001b[1;34mf\"The {param_name!r} parameter of {caller_name} must be\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;34mf\" {constraints_str}. Got {param_val!r} instead.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidParameterError\u001b[0m: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead."
     ]
    }
   ],
   "source": [
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "def find_accuracy(x):\n",
    "    model = DecisionTreeClassifier(\n",
    "        min_samples_split=int(x[0]),\n",
    "        max_depth=int(x[1])\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return 1 - accuracy\n",
    "\n",
    "result = differential_evolution(find_accuracy, [(0, 1000), (0, 1000)])\n",
    "print(result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "7990pIHMQYnF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.5405055087491899\n",
      "Dados de treino:  0.5273994811932555\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.9513618677042801\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.9273670557717251\n",
      "-\n",
      "Dados de teste:  0.8101101749837978\n",
      "Dados de treino:  0.9132619974059663\n",
      "-\n",
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.9012645914396887\n",
      "-\n",
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.8929961089494164\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8884565499351491\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8803501945525292\n",
      "-\n",
      "Dados de teste:  0.8088139987038238\n",
      "Dados de treino:  0.872568093385214\n",
      "-\n",
      "Dados de teste:  0.8152948801036941\n",
      "Dados de treino:  0.8646238651102465\n",
      "-\n",
      "Dados de teste:  0.812702527543746\n",
      "Dados de treino:  0.8599221789883269\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8574902723735408\n",
      "-\n",
      "Dados de teste:  0.8114063512637719\n",
      "Dados de treino:  0.855544747081712\n",
      "-\n",
      "Dados de teste:  0.8152948801036941\n",
      "Dados de treino:  0.8493839169909209\n",
      "-\n",
      "Dados de teste:  0.81399870382372\n",
      "Dados de treino:  0.8493839169909209\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8448443579766537\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8367380025940337\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8367380025940337\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.836413748378729\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8357652399481194\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8354409857328146\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8354409857328146\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.834792477302205\n",
      "-\n",
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.8271725032425421\n",
      "-\n",
      "Dados de teste:  0.797796500324044\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8029812054439404\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.7887232663642255\n",
      "Dados de treino:  0.9990272373540856\n",
      "-\n",
      "Dados de teste:  0.7835385612443292\n",
      "Dados de treino:  0.9523346303501945\n",
      "-\n",
      "Dados de teste:  0.7900194426441997\n",
      "Dados de treino:  0.9246108949416343\n",
      "-\n",
      "Dados de teste:  0.7952041477640959\n",
      "Dados de treino:  0.9113164721141375\n",
      "-\n",
      "Dados de teste:  0.7958522359040829\n",
      "Dados de treino:  0.9001297016861219\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8931582360570688\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.8827821011673151\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8737029831387808\n",
      "-\n",
      "Dados de teste:  0.813350615683733\n",
      "Dados de treino:  0.8654345006485085\n",
      "-\n",
      "Dados de teste:  0.8114063512637719\n",
      "Dados de treino:  0.8604085603112841\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8576523994811932\n",
      "-\n",
      "Dados de teste:  0.8101101749837978\n",
      "Dados de treino:  0.8561932555123216\n",
      "-\n",
      "Dados de teste:  0.812702527543746\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.813350615683733\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.8454928664072633\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8373865110246433\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.8377107652399481\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8370622568093385\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8362516212710766\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8359273670557718\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8354409857328146\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.834792477302205\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8271725032425421\n",
      "-\n",
      "Dados de teste:  0.797796500324044\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.778353856124433\n",
      "Dados de treino:  1.0\n",
      "-\n",
      "Dados de teste:  0.7828904731043422\n",
      "Dados de treino:  0.9539559014267186\n",
      "-\n",
      "Dados de teste:  0.7945560596241089\n",
      "Dados de treino:  0.9267185473411155\n",
      "-\n",
      "Dados de teste:  0.7932598833441348\n",
      "Dados de treino:  0.9100194552529183\n",
      "-\n",
      "Dados de teste:  0.797796500324044\n",
      "Dados de treino:  0.9002918287937743\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8933203631647212\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8829442282749675\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.873378728923476\n",
      "-\n",
      "Dados de teste:  0.813350615683733\n",
      "Dados de treino:  0.8660830090791181\n",
      "-\n",
      "Dados de teste:  0.8088139987038238\n",
      "Dados de treino:  0.8607328145265889\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8576523994811932\n",
      "-\n",
      "Dados de teste:  0.812702527543746\n",
      "Dados de treino:  0.8561932555123216\n",
      "-\n",
      "Dados de teste:  0.812702527543746\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8120544394037589\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.8454928664072633\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8373865110246433\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8377107652399481\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8370622568093385\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8362516212710766\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8359273670557718\n",
      "-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8351167315175098\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.834792477302205\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8276588845654993\n",
      "-\n",
      "Dados de teste:  0.797796500324044\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8029812054439404\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.7822423849643552\n",
      "Dados de treino:  1.0\n",
      "-\n",
      "Dados de teste:  0.7880751782242384\n",
      "Dados de treino:  0.9528210116731517\n",
      "-\n",
      "Dados de teste:  0.7939079714841218\n",
      "Dados de treino:  0.9254215304798963\n",
      "-\n",
      "Dados de teste:  0.7887232663642255\n",
      "Dados de treino:  0.9111543450064851\n",
      "-\n",
      "Dados de teste:  0.7919637070641607\n",
      "Dados de treino:  0.8999675745784695\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8933203631647212\n",
      "-\n",
      "Dados de teste:  0.8042773817239145\n",
      "Dados de treino:  0.8832684824902723\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8737029831387808\n",
      "-\n",
      "Dados de teste:  0.812702527543746\n",
      "Dados de treino:  0.8660830090791181\n",
      "-\n",
      "Dados de teste:  0.8107582631237849\n",
      "Dados de treino:  0.8607328145265889\n",
      "-\n",
      "Dados de teste:  0.8088139987038238\n",
      "Dados de treino:  0.8573281452658884\n",
      "-\n",
      "Dados de teste:  0.8114063512637719\n",
      "Dados de treino:  0.8561932555123216\n",
      "-\n",
      "Dados de teste:  0.814646791963707\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.813350615683733\n",
      "Dados de treino:  0.8500324254215305\n",
      "-\n",
      "Dados de teste:  0.8036292935839274\n",
      "Dados de treino:  0.8454928664072633\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8373865110246433\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8373865110246433\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8365758754863813\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8362516212710766\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8359273670557718\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.835603112840467\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8352788586251622\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8276588845654993\n",
      "-\n",
      "Dados de teste:  0.797796500324044\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.7731691510045366\n",
      "Dados de treino:  1.0\n",
      "-\n",
      "Dados de teste:  0.7854828256642904\n",
      "Dados de treino:  0.9528210116731517\n",
      "-\n",
      "Dados de teste:  0.7939079714841218\n",
      "Dados de treino:  0.9252594033722439\n",
      "-\n",
      "Dados de teste:  0.7958522359040829\n",
      "Dados de treino:  0.9114785992217899\n",
      "-\n",
      "Dados de teste:  0.7958522359040829\n",
      "Dados de treino:  0.8999675745784695\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.892023346303502\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.8827821011673151\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8737029831387808\n",
      "-\n",
      "Dados de teste:  0.814646791963707\n",
      "Dados de treino:  0.8660830090791181\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8613813229571985\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8583009079118028\n",
      "-\n",
      "Dados de teste:  0.812702527543746\n",
      "Dados de treino:  0.8558690012970168\n",
      "-\n",
      "Dados de teste:  0.8152948801036941\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.812702527543746\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8454928664072633\n",
      "-\n",
      "Dados de teste:  0.8088139987038238\n",
      "Dados de treino:  0.8373865110246433\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8372243839169909\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8365758754863813\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8357652399481194\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8359273670557718\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8359273670557718\n",
      "-\n",
      "Dados de teste:  0.8088139987038238\n",
      "Dados de treino:  0.834792477302205\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8276588845654993\n",
      "-\n",
      "Dados de teste:  0.7971484121840571\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8029812054439404\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.7744653272845107\n",
      "Dados de treino:  1.0\n",
      "-\n",
      "Dados de teste:  0.7874270900842515\n",
      "Dados de treino:  0.9546044098573282\n",
      "-\n",
      "Dados de teste:  0.7945560596241089\n",
      "Dados de treino:  0.9263942931258107\n",
      "-\n",
      "Dados de teste:  0.7926117952041478\n",
      "Dados de treino:  0.9098573281452659\n",
      "-\n",
      "Dados de teste:  0.797796500324044\n",
      "Dados de treino:  0.8999675745784695\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.892023346303502\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.8829442282749675\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8743514915693904\n",
      "-\n",
      "Dados de teste:  0.8152948801036941\n",
      "Dados de treino:  0.8654345006485085\n",
      "-\n",
      "Dados de teste:  0.8094620868438107\n",
      "Dados de treino:  0.8613813229571985\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8583009079118028\n",
      "-\n",
      "Dados de teste:  0.8101101749837978\n",
      "Dados de treino:  0.8561932555123216\n",
      "-\n",
      "Dados de teste:  0.812702527543746\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.813350615683733\n",
      "Dados de treino:  0.8500324254215305\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.8454928664072633\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8373865110246433\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8373865110246433\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8370622568093385\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8357652399481194\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8359273670557718\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.835603112840467\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8352788586251622\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8271725032425421\n",
      "-\n",
      "Dados de teste:  0.797796500324044\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8029812054439404\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.7939079714841218\n",
      "Dados de treino:  1.0\n",
      "-\n",
      "Dados de teste:  0.7861309138042774\n",
      "Dados de treino:  0.9528210116731517\n",
      "-\n",
      "Dados de teste:  0.7984445884640311\n",
      "Dados de treino:  0.9255836575875487\n",
      "-\n",
      "Dados de teste:  0.7932598833441348\n",
      "Dados de treino:  0.9108300907911803\n",
      "-\n",
      "Dados de teste:  0.7932598833441348\n",
      "Dados de treino:  0.8996433203631647\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8933203631647212\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8829442282749675\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.873378728923476\n",
      "-\n",
      "Dados de teste:  0.8152948801036941\n",
      "Dados de treino:  0.8654345006485085\n",
      "-\n",
      "Dados de teste:  0.8094620868438107\n",
      "Dados de treino:  0.8607328145265889\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de treino:  0.8583009079118028\n",
      "-\n",
      "Dados de teste:  0.8114063512637719\n",
      "Dados de treino:  0.8558690012970168\n",
      "-\n",
      "Dados de teste:  0.814646791963707\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8120544394037589\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8454928664072633\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8377107652399481\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8372243839169909\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8370622568093385\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8354409857328146\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8354409857328146\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8359273670557718\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8349546044098574\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8276588845654993\n",
      "-\n",
      "Dados de teste:  0.7971484121840571\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.7712248865845756\n",
      "Dados de treino:  1.0\n",
      "-\n",
      "Dados de teste:  0.7835385612443292\n",
      "Dados de treino:  0.9537937743190662\n",
      "-\n",
      "Dados de teste:  0.7932598833441348\n",
      "Dados de treino:  0.9250972762645915\n",
      "-\n",
      "Dados de teste:  0.7932598833441348\n",
      "Dados de treino:  0.9109922178988327\n",
      "-\n",
      "Dados de teste:  0.7971484121840571\n",
      "Dados de treino:  0.9001297016861219\n",
      "-\n",
      "Dados de teste:  0.8042773817239145\n",
      "Dados de treino:  0.8933203631647212\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8827821011673151\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.873378728923476\n",
      "-\n",
      "Dados de teste:  0.81399870382372\n",
      "Dados de treino:  0.8654345006485085\n",
      "-\n",
      "Dados de teste:  0.8114063512637719\n",
      "Dados de treino:  0.8604085603112841\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8576523994811932\n",
      "-\n",
      "Dados de teste:  0.8107582631237849\n",
      "Dados de treino:  0.8561932555123216\n",
      "-\n",
      "Dados de teste:  0.8152948801036941\n",
      "Dados de treino:  0.8500324254215305\n",
      "-\n",
      "Dados de teste:  0.812702527543746\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8042773817239145\n",
      "Dados de treino:  0.8454928664072633\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8373865110246433\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8373865110246433\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8365758754863813\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8362516212710766\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8354409857328146\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8354409857328146\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8352788586251622\n",
      "-\n",
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.8271725032425421\n",
      "-\n",
      "Dados de teste:  0.797796500324044\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.778353856124433\n",
      "Dados de treino:  1.0\n",
      "-\n",
      "Dados de teste:  0.780946208684381\n",
      "Dados de treino:  0.9531452658884566\n",
      "-\n",
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.9273670557717251\n",
      "-\n",
      "Dados de teste:  0.7939079714841218\n",
      "Dados de treino:  0.9098573281452659\n",
      "-\n",
      "Dados de teste:  0.7990926766040182\n",
      "Dados de treino:  0.9004539559014267\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8933203631647212\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8827821011673151\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.873378728923476\n",
      "-\n",
      "Dados de teste:  0.8159429682436812\n",
      "Dados de treino:  0.8654345006485085\n",
      "-\n",
      "Dados de teste:  0.8101101749837978\n",
      "Dados de treino:  0.8613813229571985\n",
      "-\n",
      "Dados de teste:  0.8088139987038238\n",
      "Dados de treino:  0.8576523994811932\n",
      "-\n",
      "Dados de teste:  0.812702527543746\n",
      "Dados de treino:  0.8561932555123216\n",
      "-\n",
      "Dados de teste:  0.81399870382372\n",
      "Dados de treino:  0.8500324254215305\n",
      "-\n",
      "Dados de teste:  0.812702527543746\n",
      "Dados de treino:  0.8500324254215305\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8454928664072633\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8377107652399481\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8372243839169909\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8370622568093385\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8357652399481194\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8354409857328146\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8359273670557718\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8352788586251622\n",
      "-\n",
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.8271725032425421\n",
      "-\n",
      "Dados de teste:  0.7971484121840571\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8029812054439404\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.7815942968243681\n",
      "Dados de treino:  1.0\n",
      "-\n",
      "Dados de teste:  0.7841866493843163\n",
      "Dados de treino:  0.9539559014267186\n",
      "-\n",
      "Dados de teste:  0.7952041477640959\n",
      "Dados de treino:  0.9255836575875487\n",
      "-\n",
      "Dados de teste:  0.7952041477640959\n",
      "Dados de treino:  0.9122892347600519\n",
      "-\n",
      "Dados de teste:  0.7952041477640959\n",
      "Dados de treino:  0.8996433203631647\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8918612191958496\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8832684824902723\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.873378728923476\n",
      "-\n",
      "Dados de teste:  0.812702527543746\n",
      "Dados de treino:  0.8660830090791181\n",
      "-\n",
      "Dados de teste:  0.8101101749837978\n",
      "Dados de treino:  0.8613813229571985\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.857976653696498\n",
      "-\n",
      "Dados de teste:  0.812702527543746\n",
      "Dados de treino:  0.8561932555123216\n",
      "-\n",
      "Dados de teste:  0.813350615683733\n",
      "Dados de treino:  0.8500324254215305\n",
      "-\n",
      "Dados de teste:  0.8114063512637719\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8451686121919585\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8373865110246433\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.8372243839169909\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8365758754863813\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8362516212710766\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8354409857328146\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8359273670557718\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.834792477302205\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8276588845654993\n",
      "-\n",
      "Dados de teste:  0.797796500324044\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8029812054439404\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.778353856124433\n",
      "Dados de treino:  1.0\n",
      "-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de teste:  0.7848347375243033\n",
      "Dados de treino:  0.953307392996109\n",
      "-\n",
      "Dados de teste:  0.7939079714841218\n",
      "Dados de treino:  0.9259079118028535\n",
      "-\n",
      "Dados de teste:  0.7945560596241089\n",
      "Dados de treino:  0.9106679636835279\n",
      "-\n",
      "Dados de teste:  0.797796500324044\n",
      "Dados de treino:  0.9004539559014267\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8933203631647212\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8827821011673151\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8740272373540856\n",
      "-\n",
      "Dados de teste:  0.812702527543746\n",
      "Dados de treino:  0.8660830090791181\n",
      "-\n",
      "Dados de teste:  0.8094620868438107\n",
      "Dados de treino:  0.8607328145265889\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.857976653696498\n",
      "-\n",
      "Dados de teste:  0.8120544394037589\n",
      "Dados de treino:  0.8561932555123216\n",
      "-\n",
      "Dados de teste:  0.81399870382372\n",
      "Dados de treino:  0.8500324254215305\n",
      "-\n",
      "Dados de teste:  0.8120544394037589\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8042773817239145\n",
      "Dados de treino:  0.8454928664072633\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8377107652399481\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8372243839169909\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.8370622568093385\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8362516212710766\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8359273670557718\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8354409857328146\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8352788586251622\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8276588845654993\n",
      "-\n",
      "Dados de teste:  0.797796500324044\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8029812054439404\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.7777057679844459\n",
      "Dados de treino:  1.0\n",
      "-\n",
      "Dados de teste:  0.7854828256642904\n",
      "Dados de treino:  0.9526588845654993\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.9265564202334631\n",
      "-\n",
      "Dados de teste:  0.7919637070641607\n",
      "Dados de treino:  0.9111543450064851\n",
      "-\n",
      "Dados de teste:  0.797796500324044\n",
      "Dados de treino:  0.9004539559014267\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.8916990920881972\n",
      "-\n",
      "Dados de teste:  0.8029812054439404\n",
      "Dados de treino:  0.88310635538262\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8737029831387808\n",
      "-\n",
      "Dados de teste:  0.8152948801036941\n",
      "Dados de treino:  0.8657587548638133\n",
      "-\n",
      "Dados de teste:  0.8101101749837978\n",
      "Dados de treino:  0.8613813229571985\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8583009079118028\n",
      "-\n",
      "Dados de teste:  0.8114063512637719\n",
      "Dados de treino:  0.8561932555123216\n",
      "-\n",
      "Dados de teste:  0.813350615683733\n",
      "Dados de treino:  0.8500324254215305\n",
      "-\n",
      "Dados de teste:  0.813350615683733\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8042773817239145\n",
      "Dados de treino:  0.8454928664072633\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8373865110246433\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8377107652399481\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8365758754863813\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8357652399481194\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8354409857328146\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8351167315175098\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8352788586251622\n",
      "-\n",
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.8271725032425421\n",
      "-\n",
      "Dados de teste:  0.7971484121840571\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8029812054439404\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.7731691510045366\n",
      "Dados de treino:  1.0\n",
      "-\n",
      "Dados de teste:  0.7880751782242384\n",
      "Dados de treino:  0.9544422827496758\n",
      "-\n",
      "Dados de teste:  0.7990926766040182\n",
      "Dados de treino:  0.9262321660181583\n",
      "-\n",
      "Dados de teste:  0.7945560596241089\n",
      "Dados de treino:  0.9096952010376135\n",
      "-\n",
      "Dados de teste:  0.79650032404407\n",
      "Dados de treino:  0.9004539559014267\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.8918612191958496\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8827821011673151\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8743514915693904\n",
      "-\n",
      "Dados de teste:  0.8159429682436812\n",
      "Dados de treino:  0.8654345006485085\n",
      "-\n",
      "Dados de teste:  0.8114063512637719\n",
      "Dados de treino:  0.8604085603112841\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8576523994811932\n",
      "-\n",
      "Dados de teste:  0.8114063512637719\n",
      "Dados de treino:  0.8561932555123216\n",
      "-\n",
      "Dados de teste:  0.8120544394037589\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.81399870382372\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8454928664072633\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8377107652399481\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8377107652399481\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8365758754863813\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8362516212710766\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8354409857328146\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8359273670557718\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8349546044098574\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8276588845654993\n",
      "-\n",
      "Dados de teste:  0.7971484121840571\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8029812054439404\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.780946208684381\n",
      "Dados de treino:  1.0\n",
      "-\n",
      "Dados de teste:  0.7835385612443292\n",
      "Dados de treino:  0.9534695201037614\n",
      "-\n",
      "Dados de teste:  0.7926117952041478\n",
      "Dados de treino:  0.9260700389105059\n",
      "-\n",
      "Dados de teste:  0.7984445884640311\n",
      "Dados de treino:  0.9124513618677043\n",
      "-\n",
      "Dados de teste:  0.7971484121840571\n",
      "Dados de treino:  0.9004539559014267\n",
      "-\n",
      "Dados de teste:  0.8042773817239145\n",
      "Dados de treino:  0.8933203631647212\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8826199740596627\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8743514915693904\n",
      "-\n",
      "Dados de teste:  0.8159429682436812\n",
      "Dados de treino:  0.8654345006485085\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8613813229571985\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8573281452658884\n",
      "-\n",
      "Dados de teste:  0.8120544394037589\n",
      "Dados de treino:  0.8558690012970168\n",
      "-\n",
      "Dados de teste:  0.813350615683733\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.813350615683733\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8042773817239145\n",
      "Dados de treino:  0.8454928664072633\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8377107652399481\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8373865110246433\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.8370622568093385\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8359273670557718\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8359273670557718\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8354409857328146\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8352788586251622\n",
      "-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.8271725032425421\n",
      "-\n",
      "Dados de teste:  0.797796500324044\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8029812054439404\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.780946208684381\n",
      "Dados de treino:  1.0\n",
      "-\n",
      "Dados de teste:  0.7848347375243033\n",
      "Dados de treino:  0.9534695201037614\n",
      "-\n",
      "Dados de teste:  0.7932598833441348\n",
      "Dados de treino:  0.9244487678339819\n",
      "-\n",
      "Dados de teste:  0.7893713545042126\n",
      "Dados de treino:  0.9098573281452659\n",
      "-\n",
      "Dados de teste:  0.7990926766040182\n",
      "Dados de treino:  0.9001297016861219\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.8918612191958496\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.88310635538262\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8737029831387808\n",
      "-\n",
      "Dados de teste:  0.81399870382372\n",
      "Dados de treino:  0.8654345006485085\n",
      "-\n",
      "Dados de teste:  0.8088139987038238\n",
      "Dados de treino:  0.8613813229571985\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8583009079118028\n",
      "-\n",
      "Dados de teste:  0.8101101749837978\n",
      "Dados de treino:  0.8561932555123216\n",
      "-\n",
      "Dados de teste:  0.812702527543746\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8120544394037589\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8451686121919585\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8377107652399481\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8372243839169909\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8365758754863813\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8357652399481194\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8354409857328146\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8359273670557718\n",
      "-\n",
      "Dados de teste:  0.8094620868438107\n",
      "Dados de treino:  0.834792477302205\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8276588845654993\n",
      "-\n",
      "Dados de teste:  0.7971484121840571\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.7874270900842515\n",
      "Dados de treino:  1.0\n",
      "-\n",
      "Dados de teste:  0.7867790019442644\n",
      "Dados de treino:  0.954118028534371\n",
      "-\n",
      "Dados de teste:  0.7990926766040182\n",
      "Dados de treino:  0.9268806744487679\n",
      "-\n",
      "Dados de teste:  0.7952041477640959\n",
      "Dados de treino:  0.9111543450064851\n",
      "-\n",
      "Dados de teste:  0.797796500324044\n",
      "Dados de treino:  0.9002918287937743\n",
      "-\n",
      "Dados de teste:  0.8042773817239145\n",
      "Dados de treino:  0.8915369649805448\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8829442282749675\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8743514915693904\n",
      "-\n",
      "Dados de teste:  0.814646791963707\n",
      "Dados de treino:  0.8660830090791181\n",
      "-\n",
      "Dados de teste:  0.812702527543746\n",
      "Dados de treino:  0.8604085603112841\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8573281452658884\n",
      "-\n",
      "Dados de teste:  0.8114063512637719\n",
      "Dados de treino:  0.8561932555123216\n",
      "-\n",
      "Dados de teste:  0.814646791963707\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.812702527543746\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8451686121919585\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8370622568093385\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8377107652399481\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8365758754863813\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8362516212710766\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8354409857328146\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8359273670557718\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8352788586251622\n",
      "-\n",
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.8271725032425421\n",
      "-\n",
      "Dados de teste:  0.7971484121840571\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.778353856124433\n",
      "Dados de treino:  1.0\n",
      "-\n",
      "Dados de teste:  0.7822423849643552\n",
      "Dados de treino:  0.9526588845654993\n",
      "-\n",
      "Dados de teste:  0.7990926766040182\n",
      "Dados de treino:  0.9262321660181583\n",
      "-\n",
      "Dados de teste:  0.7926117952041478\n",
      "Dados de treino:  0.9098573281452659\n",
      "-\n",
      "Dados de teste:  0.79650032404407\n",
      "Dados de treino:  0.9004539559014267\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8931582360570688\n",
      "-\n",
      "Dados de teste:  0.8042773817239145\n",
      "Dados de treino:  0.8827821011673151\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8737029831387808\n",
      "-\n",
      "Dados de teste:  0.8120544394037589\n",
      "Dados de treino:  0.8660830090791181\n",
      "-\n",
      "Dados de teste:  0.8101101749837978\n",
      "Dados de treino:  0.8607328145265889\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8583009079118028\n",
      "-\n",
      "Dados de teste:  0.8107582631237849\n",
      "Dados de treino:  0.8561932555123216\n",
      "-\n",
      "Dados de teste:  0.813350615683733\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.814646791963707\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8454928664072633\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8377107652399481\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8377107652399481\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8365758754863813\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8357652399481194\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8359273670557718\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8359273670557718\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.834792477302205\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8276588845654993\n",
      "-\n",
      "Dados de teste:  0.797796500324044\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.7764095917044718\n",
      "Dados de treino:  1.0\n",
      "-\n",
      "Dados de teste:  0.7887232663642255\n",
      "Dados de treino:  0.9531452658884566\n",
      "-\n",
      "Dados de teste:  0.7926117952041478\n",
      "Dados de treino:  0.9259079118028535\n",
      "-\n",
      "Dados de teste:  0.7926117952041478\n",
      "Dados de treino:  0.9098573281452659\n",
      "-\n",
      "Dados de teste:  0.7971484121840571\n",
      "Dados de treino:  0.9004539559014267\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8931582360570688\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8827821011673151\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8737029831387808\n",
      "-\n",
      "Dados de teste:  0.81399870382372\n",
      "Dados de treino:  0.8660830090791181\n",
      "-\n",
      "Dados de teste:  0.8107582631237849\n",
      "Dados de treino:  0.8610570687418937\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8576523994811932\n",
      "-\n",
      "Dados de teste:  0.8094620868438107\n",
      "Dados de treino:  0.8561932555123216\n",
      "-\n",
      "Dados de teste:  0.81399870382372\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de teste:  0.813350615683733\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8451686121919585\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8370622568093385\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.8377107652399481\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8362516212710766\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8362516212710766\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8359273670557718\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.835603112840467\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8352788586251622\n",
      "-\n",
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.8271725032425421\n",
      "-\n",
      "Dados de teste:  0.797796500324044\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.7777057679844459\n",
      "Dados de treino:  1.0\n",
      "-\n",
      "Dados de teste:  0.7835385612443292\n",
      "Dados de treino:  0.9529831387808041\n",
      "-\n",
      "Dados de teste:  0.7945560596241089\n",
      "Dados de treino:  0.9242866407263295\n",
      "-\n",
      "Dados de teste:  0.7919637070641607\n",
      "Dados de treino:  0.9100194552529183\n",
      "-\n",
      "Dados de teste:  0.7919637070641607\n",
      "Dados de treino:  0.9001297016861219\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8916990920881972\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8827821011673151\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8743514915693904\n",
      "-\n",
      "Dados de teste:  0.8152948801036941\n",
      "Dados de treino:  0.8654345006485085\n",
      "-\n",
      "Dados de teste:  0.8107582631237849\n",
      "Dados de treino:  0.8613813229571985\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8583009079118028\n",
      "-\n",
      "Dados de teste:  0.8114063512637719\n",
      "Dados de treino:  0.8561932555123216\n",
      "-\n",
      "Dados de teste:  0.81399870382372\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.813350615683733\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.8454928664072633\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8373865110246433\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8373865110246433\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8362516212710766\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8357652399481194\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.835603112840467\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8354409857328146\n",
      "-\n",
      "Dados de teste:  0.8094620868438107\n",
      "Dados de treino:  0.8344682230869002\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8276588845654993\n",
      "-\n",
      "Dados de teste:  0.797796500324044\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.7835385612443292\n",
      "Dados de treino:  1.0\n",
      "-\n",
      "Dados de teste:  0.7848347375243033\n",
      "Dados de treino:  0.9531452658884566\n",
      "-\n",
      "Dados de teste:  0.7945560596241089\n",
      "Dados de treino:  0.9255836575875487\n",
      "-\n",
      "Dados de teste:  0.79650032404407\n",
      "Dados de treino:  0.9114785992217899\n",
      "-\n",
      "Dados de teste:  0.7984445884640311\n",
      "Dados de treino:  0.9004539559014267\n",
      "-\n",
      "Dados de teste:  0.8042773817239145\n",
      "Dados de treino:  0.8916990920881972\n",
      "-\n",
      "Dados de teste:  0.8042773817239145\n",
      "Dados de treino:  0.88310635538262\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8743514915693904\n",
      "-\n",
      "Dados de teste:  0.813350615683733\n",
      "Dados de treino:  0.8660830090791181\n",
      "-\n",
      "Dados de teste:  0.8107582631237849\n",
      "Dados de treino:  0.8607328145265889\n",
      "-\n",
      "Dados de teste:  0.8088139987038238\n",
      "Dados de treino:  0.8576523994811932\n",
      "-\n",
      "Dados de teste:  0.812702527543746\n",
      "Dados de treino:  0.8558690012970168\n",
      "-\n",
      "Dados de teste:  0.81399870382372\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.812702527543746\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.8454928664072633\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8377107652399481\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8372243839169909\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8370622568093385\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8362516212710766\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8359273670557718\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8354409857328146\n",
      "-\n",
      "Dados de teste:  0.8088139987038238\n",
      "Dados de treino:  0.8352788586251622\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8276588845654993\n",
      "-\n",
      "Dados de teste:  0.797796500324044\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8029812054439404\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.7815942968243681\n",
      "Dados de treino:  1.0\n",
      "-\n",
      "Dados de teste:  0.7848347375243033\n",
      "Dados de treino:  0.954928664072633\n",
      "-\n",
      "Dados de teste:  0.7919637070641607\n",
      "Dados de treino:  0.9265564202334631\n",
      "-\n",
      "Dados de teste:  0.7952041477640959\n",
      "Dados de treino:  0.9126134889753567\n",
      "-\n",
      "Dados de teste:  0.7984445884640311\n",
      "Dados de treino:  0.8999675745784695\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.892023346303502\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8827821011673151\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8737029831387808\n",
      "-\n",
      "Dados de teste:  0.81399870382372\n",
      "Dados de treino:  0.8660830090791181\n",
      "-\n",
      "Dados de teste:  0.8094620868438107\n",
      "Dados de treino:  0.8607328145265889\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8576523994811932\n",
      "-\n",
      "Dados de teste:  0.813350615683733\n",
      "Dados de treino:  0.8561932555123216\n",
      "-\n",
      "Dados de teste:  0.81399870382372\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.813350615683733\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8454928664072633\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8377107652399481\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8372243839169909\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8370622568093385\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8354409857328146\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8354409857328146\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8359273670557718\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.834792477302205\n",
      "-\n",
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.8271725032425421\n",
      "-\n",
      "Dados de teste:  0.7971484121840571\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.7835385612443292\n",
      "Dados de treino:  1.0\n",
      "-\n",
      "Dados de teste:  0.7835385612443292\n",
      "Dados de treino:  0.9531452658884566\n",
      "-\n",
      "Dados de teste:  0.7990926766040182\n",
      "Dados de treino:  0.9268806744487679\n",
      "-\n",
      "Dados de teste:  0.7945560596241089\n",
      "Dados de treino:  0.9111543450064851\n",
      "-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de teste:  0.7984445884640311\n",
      "Dados de treino:  0.9001297016861219\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8915369649805448\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8832684824902723\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8743514915693904\n",
      "-\n",
      "Dados de teste:  0.813350615683733\n",
      "Dados de treino:  0.8654345006485085\n",
      "-\n",
      "Dados de teste:  0.8107582631237849\n",
      "Dados de treino:  0.8607328145265889\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8576523994811932\n",
      "-\n",
      "Dados de teste:  0.8120544394037589\n",
      "Dados de treino:  0.8558690012970168\n",
      "-\n",
      "Dados de teste:  0.8120544394037589\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.814646791963707\n",
      "Dados de treino:  0.8500324254215305\n",
      "-\n",
      "Dados de teste:  0.8042773817239145\n",
      "Dados de treino:  0.8454928664072633\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8373865110246433\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8372243839169909\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8367380025940337\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8362516212710766\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8359273670557718\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8359273670557718\n",
      "-\n",
      "Dados de teste:  0.8088139987038238\n",
      "Dados de treino:  0.834792477302205\n",
      "-\n",
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.8271725032425421\n",
      "-\n",
      "Dados de teste:  0.797796500324044\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8029812054439404\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.7835385612443292\n",
      "Dados de treino:  1.0\n",
      "-\n",
      "Dados de teste:  0.7848347375243033\n",
      "Dados de treino:  0.9542801556420234\n",
      "-\n",
      "Dados de teste:  0.7945560596241089\n",
      "Dados de treino:  0.9250972762645915\n",
      "-\n",
      "Dados de teste:  0.7919637070641607\n",
      "Dados de treino:  0.9111543450064851\n",
      "-\n",
      "Dados de teste:  0.7971484121840571\n",
      "Dados de treino:  0.9002918287937743\n",
      "-\n",
      "Dados de teste:  0.8029812054439404\n",
      "Dados de treino:  0.8916990920881972\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8827821011673151\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8743514915693904\n",
      "-\n",
      "Dados de teste:  0.8152948801036941\n",
      "Dados de treino:  0.8660830090791181\n",
      "-\n",
      "Dados de teste:  0.8114063512637719\n",
      "Dados de treino:  0.8604085603112841\n",
      "-\n",
      "Dados de teste:  0.8088139987038238\n",
      "Dados de treino:  0.8576523994811932\n",
      "-\n",
      "Dados de teste:  0.8107582631237849\n",
      "Dados de treino:  0.8561932555123216\n",
      "-\n",
      "Dados de teste:  0.81399870382372\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.813350615683733\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8036292935839274\n",
      "Dados de treino:  0.8454928664072633\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8370622568093385\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8372243839169909\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8365758754863813\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8362516212710766\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8351167315175098\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8354409857328146\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.834792477302205\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8276588845654993\n",
      "-\n",
      "Dados de teste:  0.797796500324044\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8029812054439404\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.7900194426441997\n",
      "Dados de treino:  1.0\n",
      "-\n",
      "Dados de teste:  0.779650032404407\n",
      "Dados de treino:  0.9536316472114138\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.9265564202334631\n",
      "-\n",
      "Dados de teste:  0.7900194426441997\n",
      "Dados de treino:  0.9106679636835279\n",
      "-\n",
      "Dados de teste:  0.797796500324044\n",
      "Dados de treino:  0.9006160830090791\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.892833981841764\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8827821011673151\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8737029831387808\n",
      "-\n",
      "Dados de teste:  0.814646791963707\n",
      "Dados de treino:  0.8660830090791181\n",
      "-\n",
      "Dados de teste:  0.8107582631237849\n",
      "Dados de treino:  0.8613813229571985\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8583009079118028\n",
      "-\n",
      "Dados de teste:  0.8107582631237849\n",
      "Dados de treino:  0.8561932555123216\n",
      "-\n",
      "Dados de teste:  0.81399870382372\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8120544394037589\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.8454928664072633\n",
      "-\n",
      "Dados de teste:  0.8088139987038238\n",
      "Dados de treino:  0.8373865110246433\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.8377107652399481\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.8370622568093385\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8357652399481194\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8354409857328146\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.835603112840467\n",
      "-\n",
      "Dados de teste:  0.8088139987038238\n",
      "Dados de treino:  0.8349546044098574\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8276588845654993\n",
      "-\n",
      "Dados de teste:  0.7971484121840571\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8029812054439404\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.7802981205443941\n",
      "Dados de treino:  1.0\n",
      "-\n",
      "Dados de teste:  0.7874270900842515\n",
      "Dados de treino:  0.9546044098573282\n",
      "-\n",
      "Dados de teste:  0.7984445884640311\n",
      "Dados de treino:  0.9265564202334631\n",
      "-\n",
      "Dados de teste:  0.7952041477640959\n",
      "Dados de treino:  0.9124513618677043\n",
      "-\n",
      "Dados de teste:  0.7932598833441348\n",
      "Dados de treino:  0.9001297016861219\n",
      "-\n",
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.8916990920881972\n",
      "-\n",
      "Dados de teste:  0.8042773817239145\n",
      "Dados de treino:  0.88310635538262\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8743514915693904\n",
      "-\n",
      "Dados de teste:  0.813350615683733\n",
      "Dados de treino:  0.8654345006485085\n",
      "-\n",
      "Dados de teste:  0.8120544394037589\n",
      "Dados de treino:  0.8613813229571985\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8576523994811932\n",
      "-\n",
      "Dados de teste:  0.812702527543746\n",
      "Dados de treino:  0.8558690012970168\n",
      "-\n",
      "Dados de teste:  0.8152948801036941\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.81399870382372\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.8454928664072633\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8377107652399481\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8377107652399481\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8365758754863813\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8357652399481194\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8354409857328146\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8354409857328146\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.834792477302205\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8276588845654993\n",
      "-\n",
      "Dados de teste:  0.7971484121840571\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.7835385612443292\n",
      "Dados de treino:  1.0\n",
      "-\n",
      "Dados de teste:  0.7828904731043422\n",
      "Dados de treino:  0.9531452658884566\n",
      "-\n",
      "Dados de teste:  0.7990926766040182\n",
      "Dados de treino:  0.9270428015564203\n",
      "-\n",
      "Dados de teste:  0.7945560596241089\n",
      "Dados de treino:  0.9109922178988327\n",
      "-\n",
      "Dados de teste:  0.79650032404407\n",
      "Dados de treino:  0.9004539559014267\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.8933203631647212\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.8827821011673151\n",
      "-\n",
      "Dados de teste:  0.8036292935839274\n",
      "Dados de treino:  0.8743514915693904\n",
      "-\n",
      "Dados de teste:  0.812702527543746\n",
      "Dados de treino:  0.8660830090791181\n",
      "-\n",
      "Dados de teste:  0.8107582631237849\n",
      "Dados de treino:  0.8613813229571985\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8573281452658884\n",
      "-\n",
      "Dados de teste:  0.812702527543746\n",
      "Dados de treino:  0.8558690012970168\n",
      "-\n",
      "Dados de teste:  0.8120544394037589\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.812702527543746\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.8454928664072633\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8373865110246433\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8372243839169909\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.8370622568093385\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8357652399481194\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.835603112840467\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8354409857328146\n",
      "-\n",
      "Dados de teste:  0.8094620868438107\n",
      "Dados de treino:  0.834792477302205\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8271725032425421\n",
      "-\n",
      "Dados de teste:  0.7971484121840571\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8029812054439404\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.7802981205443941\n",
      "Dados de treino:  1.0\n",
      "-\n",
      "Dados de teste:  0.7815942968243681\n",
      "Dados de treino:  0.9523346303501945\n",
      "-\n",
      "Dados de teste:  0.7932598833441348\n",
      "Dados de treino:  0.9250972762645915\n",
      "-\n",
      "Dados de teste:  0.7919637070641607\n",
      "Dados de treino:  0.9105058365758755\n",
      "-\n",
      "Dados de teste:  0.7926117952041478\n",
      "Dados de treino:  0.9001297016861219\n",
      "-\n",
      "Dados de teste:  0.8036292935839274\n",
      "Dados de treino:  0.8933203631647212\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8829442282749675\n",
      "-\n",
      "Dados de teste:  0.8088139987038238\n",
      "Dados de treino:  0.8737029831387808\n",
      "-\n",
      "Dados de teste:  0.813350615683733\n",
      "Dados de treino:  0.8660830090791181\n",
      "-\n",
      "Dados de teste:  0.8101101749837978\n",
      "Dados de treino:  0.8607328145265889\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8576523994811932\n",
      "-\n",
      "Dados de teste:  0.8101101749837978\n",
      "Dados de treino:  0.8561932555123216\n",
      "-\n",
      "Dados de teste:  0.812702527543746\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.812702527543746\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8454928664072633\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8377107652399481\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.8377107652399481\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8370622568093385\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8357652399481194\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8354409857328146\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8359273670557718\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8352788586251622\n",
      "-\n",
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.8271725032425421\n",
      "-\n",
      "Dados de teste:  0.7971484121840571\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8029812054439404\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.7790019442644199\n",
      "Dados de treino:  1.0\n",
      "-\n",
      "Dados de teste:  0.7880751782242384\n",
      "Dados de treino:  0.9547665369649806\n",
      "-\n",
      "Dados de teste:  0.7945560596241089\n",
      "Dados de treino:  0.9247730220492867\n",
      "-\n",
      "Dados de teste:  0.7926117952041478\n",
      "Dados de treino:  0.9111543450064851\n",
      "-\n",
      "Dados de teste:  0.7958522359040829\n",
      "Dados de treino:  0.9002918287937743\n",
      "-\n",
      "Dados de teste:  0.8042773817239145\n",
      "Dados de treino:  0.8933203631647212\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.8827821011673151\n",
      "-\n",
      "Dados de teste:  0.8088139987038238\n",
      "Dados de treino:  0.8737029831387808\n",
      "-\n",
      "Dados de teste:  0.812702527543746\n",
      "Dados de treino:  0.8654345006485085\n",
      "-\n",
      "Dados de teste:  0.8101101749837978\n",
      "Dados de treino:  0.8613813229571985\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8576523994811932\n",
      "-\n",
      "Dados de teste:  0.813350615683733\n",
      "Dados de treino:  0.8561932555123216\n",
      "-\n",
      "Dados de teste:  0.8120544394037589\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.814646791963707\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8451686121919585\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8373865110246433\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8377107652399481\n",
      "-\n",
      "Dados de teste:  0.8042773817239145\n",
      "Dados de treino:  0.8370622568093385\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8357652399481194\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8354409857328146\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8351167315175098\n",
      "-\n",
      "Dados de teste:  0.8094620868438107\n",
      "Dados de treino:  0.834792477302205\n",
      "-\n",
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.8271725032425421\n",
      "-\n",
      "Dados de teste:  0.797796500324044\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8010369410239793\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8029812054439404\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n",
      "Dados de teste:  0.7887232663642255\n",
      "Dados de treino:  1.0\n",
      "-\n",
      "Dados de teste:  0.7841866493843163\n",
      "Dados de treino:  0.9529831387808041\n",
      "-\n",
      "Dados de teste:  0.7952041477640959\n",
      "Dados de treino:  0.9249351491569391\n",
      "-\n",
      "Dados de teste:  0.7932598833441348\n",
      "Dados de treino:  0.9098573281452659\n",
      "-\n",
      "Dados de teste:  0.7926117952041478\n",
      "Dados de treino:  0.8999675745784695\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8929961089494164\n",
      "-\n",
      "Dados de teste:  0.8055735580038885\n",
      "Dados de treino:  0.88310635538262\n",
      "-\n",
      "Dados de teste:  0.8075178224238496\n",
      "Dados de treino:  0.8743514915693904\n",
      "-\n",
      "Dados de teste:  0.8159429682436812\n",
      "Dados de treino:  0.8660830090791181\n",
      "-\n",
      "Dados de teste:  0.8088139987038238\n",
      "Dados de treino:  0.8613813229571985\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8576523994811932\n",
      "-\n",
      "Dados de teste:  0.8114063512637719\n",
      "Dados de treino:  0.8558690012970168\n",
      "-\n",
      "Dados de teste:  0.813350615683733\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.812702527543746\n",
      "Dados de treino:  0.8503566796368353\n",
      "-\n",
      "Dados de teste:  0.8049254698639015\n",
      "Dados de treino:  0.8454928664072633\n",
      "-\n",
      "Dados de teste:  0.8088139987038238\n",
      "Dados de treino:  0.8370622568093385\n",
      "-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8372243839169909\n",
      "-\n",
      "Dados de teste:  0.8081659105638367\n",
      "Dados de treino:  0.8365758754863813\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8357652399481194\n",
      "-\n",
      "Dados de teste:  0.8068697342838627\n",
      "Dados de treino:  0.8354409857328146\n",
      "-\n",
      "Dados de teste:  0.8062216461438756\n",
      "Dados de treino:  0.8359273670557718\n",
      "-\n",
      "Dados de teste:  0.8088139987038238\n",
      "Dados de treino:  0.8344682230869002\n",
      "-\n",
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.8271725032425421\n",
      "-\n",
      "Dados de teste:  0.7971484121840571\n",
      "Dados de treino:  0.8236057068741893\n",
      "-\n",
      "Dados de teste:  0.7997407647440052\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8003888528839922\n",
      "Dados de treino:  0.8232814526588845\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8213359273670557\n",
      "-\n",
      "Dados de teste:  0.8016850291639663\n",
      "Dados de treino:  0.8210116731517509\n",
      "-\n",
      "Dados de teste:  0.8023331173039533\n",
      "Dados de treino:  0.8206874189364461\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "for j in range(1, 300, 10):\n",
    "  for i in range(2, 300, 10):\n",
    "    model = DecisionTreeClassifier(\n",
    "        min_samples_split=i,\n",
    "        max_depth=j\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Dados de teste: \", accuracy)\n",
    "\n",
    "    y_pred = model.predict(X_train)\n",
    "    accuracy_train_data = accuracy_score(y_train, y_pred)\n",
    "    print(\"Dados de treino: \", accuracy_train_data)\n",
    "\n",
    "    print(\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "lF5_OH0yVKLQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(\n",
    "        min_samples_split=120,\n",
    "        max_depth=120\n",
    "    ),\n",
    "    \"Support Vector Machine\" : SVC(),\n",
    "    \"K-nearest Neighbors\" : KNeighborsClassifier(\n",
    "        n_neighbors=3  #kmeans\n",
    "    ),\n",
    "    \"Random Forest\" : RandomForestClassifier(\n",
    "        min_samples_split=120,\n",
    "        max_depth=120\n",
    "    ),\n",
    "    \"Gaussian Naive Bayes\" : GaussianNB(),\n",
    "    \"Ensemble Boosting\" : HistGradientBoostingClassifier(),\n",
    "    \"Ensemble Bagging\" : BaggingClassifier(SVC(),\n",
    "        max_samples=0.5, max_features=0.5\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BLamHOCQWoih",
    "outputId": "77ae353d-7bff-405b-e4c0-2da0ea2d30d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "score: 0.7958522359040829\n",
      "score dados treino: 0.8404669260700389\n",
      "\n",
      "\n",
      "Support Vector Machine\n",
      "score: 0.8509397278029812\n",
      "score dados treino: 0.8623540856031129\n",
      "\n",
      "\n",
      "K-nearest Neighbors\n",
      "score: 0.7913156189241737\n",
      "score dados treino: 0.8850518806744487\n",
      "\n",
      "\n",
      "Random Forest\n",
      "score: 0.8269604666234608\n",
      "score dados treino: 0.8608949416342413\n",
      "\n",
      "\n",
      "Gaussian Naive Bayes\n",
      "score: 0.814646791963707\n",
      "score dados treino: 0.8018806744487679\n",
      "\n",
      "\n",
      "Ensemble Boosting\n",
      "score: 0.8438107582631238\n",
      "score dados treino: 1.0\n",
      "\n",
      "\n",
      "Ensemble Bagging\n",
      "score: 0.8269604666234608\n",
      "score dados treino: 0.8289559014267186\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in models:\n",
    "    model = models[key]\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    score = accuracy_score(y_pred, y_test)\n",
    "    print(f\"{key}\")\n",
    "    print(f\"score: {score}\")\n",
    "\n",
    "    y_pred = model.predict(X_train)\n",
    "    score = accuracy_score(y_pred, y_train)\n",
    "    print(f\"score dados treino: {score}\")\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training set only.\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Make an instance of the Model\n",
    "pca = PCA(.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=0.95)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=0.95)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA(n_components=0.95)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all parameters not specified are set to their defaults\n",
    "# default solver is incredibly slow which is why it was changed to 'lbfgs'\n",
    "logisticRegr = LogisticRegression(solver = 'lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\disrct\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict for One Observation (image)\n",
    "logisticRegr.predict(X_test[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 3, 2, 3, 2, 1, 2, 1, 3], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict for One Observation (image)\n",
    "logisticRegr.predict(X_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8457550226830849"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=120, min_samples_split=120)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=120, min_samples_split=120)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=120, min_samples_split=120)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(\n",
    "    min_samples_split=120,\n",
    "    max_depth=120\n",
    ")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de teste:  0.7958522359040829\n",
      "Dados de treino:  0.8404669260700389\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Dados de teste: \", accuracy)\n",
    "\n",
    "y_pred = model.predict(X_train)\n",
    "accuracy_train_data = accuracy_score(y_train, y_pred)\n",
    "print(\"Dados de treino: \", accuracy_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['myModel.pkl']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(model, \"myModel.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = load(\"myModel.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\disrct\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "prediction = myModel.predict([[93, 93, 78000000.0, 320000.0, 34, 170, 72, 470, 19,\n",
    "                            1.0, 4, 0, 4, 4, 5, 7, 9, 1, 144300000.0, 85.0, 92.0,\n",
    "                            91.0, 95.0, 34.0, 65.0, 85, 95, 70, 91, 88, 96, 93, 94,\n",
    "                            91, 96, 91, 80, 91, 94, 95, 86, 68, 72, 69, 94, 44, 40,\n",
    "                            93, 95, 75, 96, 20, 35, 24, 6, 11, 15, 14, 8, 0.0, 89,\n",
    "                            89, 89, 92, 93, 93, 93, 92, 93, 93, 93, 91, 87, 87, 87,\n",
    "                            91, 66, 64, 64, 64, 66, 61, 50, 50, 50, 61, 19]])\n",
    "\n",
    "if(prediction == 0):\n",
    "    print(\"Goalkeeper\")\n",
    "elif(prediction == 1):\n",
    "    print(\"Defender\")\n",
    "elif(prediction == 2):\n",
    "    print(\"Midfielder\")\n",
    "elif(prediction == 3):\n",
    "    print(\"Forward\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(inputData):\n",
    "    prediction = myModel.predict([inputData])\n",
    "\n",
    "    if(prediction == 0):\n",
    "        return \"Goalkeeper\"\n",
    "    elif(prediction == 1):\n",
    "        return \"Defender\"\n",
    "    elif(prediction == 2):\n",
    "        return \"Midfielder\"\n",
    "    elif(prediction == 3):\n",
    "        return \"Forward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8080/ (Press CTRL+C to quit)\n",
      "C:\\Users\\disrct\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "127.0.0.1 - - [14/Nov/2023 09:17:17] \"\u001b[37mPOST /prediction HTTP/1.1\u001b[0m\" 200 -\n",
      "C:\\Users\\disrct\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "127.0.0.1 - - [14/Nov/2023 09:17:24] \"\u001b[37mPOST /prediction HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, escape, request\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/prediction', methods=['POST'])\n",
    "def predictionPost():\n",
    "    data = request.json\n",
    "    return prediction(data.get('data'))\n",
    "\n",
    "app.run(port=8080)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
